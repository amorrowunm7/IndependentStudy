{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independnet Study Week 3 - Clustering / Text Processing\n",
    "\n",
    "## Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import igraph\n",
    "import pickle\n",
    "import requests\n",
    "import boilerpipe\n",
    "import opengraph\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "# Hide some silly output\n",
    "import logging\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "\n",
    "# Import everything we need from graphlab\n",
    "import graphlab as gl\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Heirarchical Clustering\n",
    "\n",
    "The only algo in the readings for clustering is (agglomerative) heirarchical clustering, which I attempt to implement here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<igraph.drawing.Plot at 0x7fedf471ab50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterGraph = igraph.Graph()\n",
    "\n",
    "# List of vertex names\n",
    "vertices = range(10)\n",
    "\n",
    "# Add vertices to the graph\n",
    "clusterGraph.add_vertices(len(vertices))\n",
    "clusterGraph.vs[\"name\"] = vertices\n",
    "\n",
    "# Setup edges\n",
    "edges = [ (0, 1), (0,2), (1, 2), (2, 3), (4,0), (3, 4), (1, 4), (4, 5), (5, 6), (6, 7), (7,8), (6,8), (6, 9), (8, 9), (7,9) ]\n",
    "clusterGraph.add_edges( edges )\n",
    "\n",
    "# Display (popup, since Cairo is a pain to install)\n",
    "layout = clusterGraph.layout(\"graphopt\")\n",
    "igraph.plot(clusterGraph, layout = layout, vertex_label=vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 2, 1, 2, 3, 4, 4, 4],\n",
       " [1, 0, 1, 2, 1, 2, 3, 4, 4, 4],\n",
       " [1, 1, 0, 1, 2, 3, 4, 5, 5, 5],\n",
       " [2, 2, 1, 0, 1, 2, 3, 4, 4, 4],\n",
       " [1, 1, 2, 1, 0, 1, 2, 3, 3, 3],\n",
       " [2, 2, 3, 2, 1, 0, 1, 2, 2, 2],\n",
       " [3, 3, 4, 3, 2, 1, 0, 1, 1, 1],\n",
       " [4, 4, 5, 4, 3, 2, 1, 0, 1, 1],\n",
       " [4, 4, 5, 4, 3, 2, 1, 1, 0, 1],\n",
       " [4, 4, 5, 4, 3, 2, 1, 1, 1, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = clusterGraph.shortest_paths_dijkstra()\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [6, 7, 8, 9], 2: [4, 5], 3: [2, 3], 4: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "#dendrogram = igraph_kite.community_edge_betweenness()\n",
    "#igraph.plot(dendrogram)\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial import distance\n",
    "\n",
    "t = 1.0\n",
    "Y = distance.squareform(distances)\n",
    "Z = hierarchy.complete(Y)  # Creates HC using farthest point linkage\n",
    "\n",
    "labels = clusterGraph.vs[\"name\"]\n",
    "\n",
    "# This partition selection is arbitrary, for illustrive purposes\n",
    "membership = list(hierarchy.fcluster(Z, t=t))\n",
    "membership\n",
    "\n",
    "# Create collection of lists for blockmodel\n",
    "partition=defaultdict(list)\n",
    "for n,p in zip(list(range(len(membership))), membership):\n",
    "    partition[p].append(labels[n])\n",
    "pprint.pprint(dict(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: \n",
      "[[0.0, 1.0, 4.0, 5.0],\n",
      " [1.0, 0.0, 3.0, 4.0],\n",
      " [4.0, 3.0, 0.0, 1.0],\n",
      " [5.0, 4.0, 1.0, 0.0]]\n",
      "Distances: \n",
      "[[0.0, 1.0, 5.0], [1.0, 0.0, 6.0], [5.0, 6.0, 0.0]]\n",
      "Distances: \n",
      "[[0.0, 5.0], [5.0, 0.0]]\n",
      "Distances: \n",
      "[[0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Custom example\n",
    "testVertices = [0, 1, 2, 3]\n",
    "testGraph = igraph.Graph()\n",
    "testGraph.add_vertices(len(testVertices))\n",
    "testGraph.vs[\"name\"] = testVertices\n",
    "\n",
    "# Setup edges\n",
    "testGraph.es[\"weight\"] = 1.0\n",
    "testEdges = [ (0, 1), (1, 2), (2, 3), (0, 2) ]\n",
    "testGraph.add_edges( testEdges )\n",
    "testGraph[0, 1] = 1\n",
    "testGraph[1, 2] = 3\n",
    "testGraph[2, 3] = 1\n",
    "testGraph[0, 2] = 5\n",
    "\n",
    "# Display (popup, since Cairo is a pain to install)\n",
    "def plotGraph(testGraph):\n",
    "    layout = testGraph.layout(\"graphopt\")\n",
    "    visual_style = {}\n",
    "    visual_style[\"vertex_label\"] = testGraph.vs[\"name\"]\n",
    "    visual_style[\"vertex_size\"] = 40\n",
    "    visual_style[\"margin\"] = 20\n",
    "    visual_style[\"edge_width\"] = [10 - edge[\"weight\"] for edge in testGraph.es]\n",
    "    igraph.plot(testGraph, layout = layout, **visual_style)\n",
    "plotGraph(testGraph)\n",
    "\n",
    "clusterNum = len(testVertices)\n",
    "clustersHist = [ {v:v for v in testVertices} ]\n",
    "nodesToCluster = testVertices[:]\n",
    "\n",
    "distHist = [ ]\n",
    "while True:\n",
    "    # Calculate shortest distance matrix from current state of graph\n",
    "    distances = testGraph.shortest_paths_dijkstra(weights=\"weight\")\n",
    "    print \"Distances: \"\n",
    "    pprint.pprint(distances)\n",
    "    distHist.append(distances)\n",
    "    \n",
    "    # Are we done?\n",
    "    if len(distances) == 1:\n",
    "        break\n",
    "    \n",
    "    # PROBLEM FOR TOMORROW: constant issues when using names versus ids. not sure how to cope\n",
    "    nodesToCluster = [v.index for v in testGraph.vs ]\n",
    "    \n",
    "    # Vertex to cluster and the closest vertex to it\n",
    "    nodeToCluster = nodesToCluster.pop(0)\n",
    "    nodeToClusterWith = distances[nodeToCluster].index(sorted(distances[nodeToCluster])[1])\n",
    "    \n",
    "    # Name version of above vertices\n",
    "    nodeToCluster_name = testGraph.vs[nodeToCluster]['name']\n",
    "    nodeToClusterWith_name = testGraph.vs[nodeToClusterWith]['name']\n",
    "\n",
    "    # Add new node for the cluster\n",
    "    testGraph.add_vertex(name=clusterNum)\n",
    "    \n",
    "    # IF there is an edge between cluster nodes, makes next calculation easier\n",
    "    testGraph.delete_edges(testGraph.es.select(_source=nodeToCluster, _target=nodeToClusterWith))  \n",
    "    \n",
    "    # Replace all old edges to the clustered node #1\n",
    "    for edge in testGraph.incident(nodeToCluster, mode=\"in\"):\n",
    "        #print edge, testGraph.es[edge].attributes()['weight']\n",
    "        #print (clusterNum, testGraph.es[edge].target)\n",
    "        testGraph.add_edges([(testGraph.vs.select(name=clusterNum)[0], testGraph.es[edge].target)])\n",
    "        testGraph[testGraph.vs.select(name=clusterNum)[0], testGraph.es[edge].target] = testGraph.es[edge].attributes()['weight']\n",
    "\n",
    "# TODO: fix this, need to get minimum weight\n",
    "#     for edge in testGraph.incident(nodeToClusterWith, mode=\"in\"):\n",
    "#         #print edge, testGraph.es[edge].attributes()['weight']\n",
    "#         #print (clusterNum, testGraph.es[edge].target)\n",
    "#         testGraph.add_edges([(clusterNum, testGraph.es[edge].target)])\n",
    "#         testGraph[clusterNum, testGraph.es[edge].target] = testGraph.es[edge].attributes()['weight']\n",
    "#         print len(testGraph.es)\n",
    "\n",
    "    # Delete the nodes that were clustered\n",
    "    testGraph.delete_vertices([nodeToCluster, nodeToClusterWith])\n",
    "    \n",
    "    # Show new graph again\n",
    "    plotGraph(testGraph)\n",
    "    \n",
    "    # Increase to get next cluster name\n",
    "    clusterNum += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2  - Text Processing\n",
    "\n",
    "Continuing from last week, I extend the textual analysis to the articles linked to tweets from the think-tank accounts. Lets start off importing statuses from pickle object, listing out our accounts and extracting all the urls we can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open content and accounts from previous week\n",
    "allStatuses = pickle.load( open( \"../Week2/allStatuses\", \"rb\" ) )\n",
    "accounts = allStatuses.keys()\n",
    "\n",
    "# Extract all the links from the crawled tweets\n",
    "links = { }\n",
    "for account in accounts:\n",
    "    links[account] = [url.expanded_url  for status in allStatuses[account] for url in status.urls ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at how boilerpipe works for a single article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Faculty Lounge Rachel Dolezal Let Go at Eastern Washington University\n",
      "Rachel Dolezal Let Go at Eastern Washington University\n",
      "June 25, 2015\n",
      ",  Spencer Irvine, Leave a comment\n",
      "The controversial adjunct professor and former head of the Spokane, Washington NAACP chapter will not be retained, in all likelihood. But, her past is more head-scratching than her recent comments on her being African-American.\n",
      "Book Review\n",
      "Have We Lost the Cultural War?\n",
      "Paul Kengor’s new book, Takedown: From Communists to Progressives, How the Left Has Sabotaged Family and Marriage, provides a detailed explanation of why, according to a new Gallup poll, “Americans are more likely now than…\n",
      ", Spencer Irvine , No Comment\n",
      "Coming to a university near you\n",
      "Before you find him on offer as a university speaker or course, you may want to read the meticulously documented story of Cop killer Mumia Abu-Jamal by former Accuracy in Academia executive director Dan Flynn.\n",
      "© Accuracy In Academia\n",
      "Receive our FREE email newsletter!\n",
      "Receive updates on our efforts to fight bias in academia, as well as the most recent publications from the Accuracy in Academia web site.\n",
      "Subscribe Now!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boiler pipe for a single article example\n",
    "from boilerpipe.extract import Extractor\n",
    "extractor = Extractor(extractor='ArticleExtractor', url=links['AccuracyInMedia'][0])\n",
    "extracted_text_default = extractor.getText()\n",
    "print extracted_text_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results are okay. There are different kinds of extractors, but this one seems to do well enough. Boilerpipe does better with articles from FAIR. Let us look at how we could use opengraph to extract information (if boilerpipe doesn't work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Dolezal Let Go at Eastern Washington University. The controversial adjunct professor and former head of the Spokane, Washington NAACP chapter will not be retained, in all likelihood. But, her past is more head-scratching than her recent comments ...\n",
      "\n",
      "Supreme Court Upholds ObamaCare, Again, in King v. Burwell  . Yup, by a 6-3 vote and the majority written by Chief Justice Roberts, ObamaCare’s illegal subsidies are ruled legal.\n",
      "\n",
      "IRS shelled out $18.8 Million to Contractors who didn’t pay Back Taxes  . Way to protect American taxpayer dollars, IRS. “The IRS granted 57 contracts worth $18.8 million to corporations with unpaid back taxes from 2012 to 2013, according to a March 26 Treasury Inspector General for Tax Administration (TIGTA) report.”\n",
      "\n",
      "Study finds less than 5% of Colleges Protect 1st Amendment Rights  . This isn’t shocking news as colleges like to impose speech codes and free speech zones on their campuses: “A new study says that less than 5 percent of colleges and universities surveyed have policies in place that respect the First Amendment right to free speech, while more than half are violating either the First Amendment […]\n",
      "\n",
      "WATCH: State Dept Admits It’s Combing Through E-mails to See Which Ones Hillary Didn’t Provide  . So Hillary isn’t completely transparent, contrary to what some liberals and media outlets are saying? We’re not surprised that there are missing e-mails.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for url in links[\"AccuracyInMedia\"][:5]:\n",
    "    og =  opengraph.OpenGraph(url=url, scrape=True)\n",
    "    print \"%s. %s\" % (og.title, og.description)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a little better, though it is not much more data. Lets use it and crawl the links for all accounts using BoilerPipe and OpenGraph as a backup in case of an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting account ips_dc\n",
      " -- extracting http://www.ips-dc.org/?p=38436 with boilerpipe\n",
      " -- extracting http://fpif.org/our-refugee-world with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/francis-v-washington/ with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38416 with boilerpipe\n",
      " -- extracting http://bit.ly/1L3dMtX with boilerpipe\n",
      " -- extracting http://bit.ly/1BAKYqo with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38414 with boilerpipe\n",
      " -- extracting http://bit.ly/1IyIUfP with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38412 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38410 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38410 with boilerpipe\n",
      " -- extracting http://bit.ly/1LiZ565 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38399 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/hacked/ with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38262 with boilerpipe\n",
      " -- extracting http://ips-dc.org/?p=38392 with boilerpipe\n",
      " -- extracting https://youtu.be/5w68-0Vr_YY with boilerpipe\n",
      " -- extracting http://bit.ly/1L3dMtX with boilerpipe\n",
      " -- extracting http://bit.ly/1LiZ565 with boilerpipe\n",
      " -- extracting http://bit.ly/1I62nII with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38392 with boilerpipe\n",
      " -- extracting http://otherwords.org/faking-it-while-the-world-burns/ with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28926 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38392 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38262 with boilerpipe\n",
      " -- extracting http://bit.ly/1ft8xHQ with boilerpipe\n",
      " -- extracting http://otherwords.org/the-year-of-the-internet-voter/ with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38392 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38318 with boilerpipe\n",
      " -- extracting http://otherwords.org/all-hacked-up/ with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38366 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/?p=38377 with boilerpipe\n",
      " -- extracting http://www.ips-dc.org/hell-on-earth/ with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28920 with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26981 with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28926 with boilerpipe\n",
      " -- extracting http://inequality.org/?p=9122 with boilerpipe\n",
      " -- failed; extracting http://inequality.org/?p=9122 with og\n",
      " -- extracting http://otherwords.org/?p=26975 with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28901 with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26971 with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26977 with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26957 with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28901 with boilerpipe\n",
      " -- extracting http://america.aljazeera.com/opinions/2015/6/the-secret-of-isils-appeal.html with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26971 with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28926 with boilerpipe\n",
      " -- extracting http://thenat.in/1Li98WU with boilerpipe\n",
      " -- extracting http://otherwords.org/?p=26981 with boilerpipe\n",
      " -- extracting http://fpif.org/?p=28920 with boilerpipe\n",
      " -- extracting http://www.alternet.org/news-amp-politics/damning-new-report-reveals-walmarts-elaborate-tax-dodging-scheme?sc=fb with boilerpipe\n",
      " -- failed; extracting http://www.alternet.org/news-amp-politics/damning-new-report-reveals-walmarts-elaborate-tax-dodging-scheme?sc=fb with og\n",
      "Starting account fairmediawatch\n",
      " -- extracting http://bit.ly/1J7XVYL with boilerpipe\n",
      " -- extracting http://bit.ly/1RxKvr6 with boilerpipe\n",
      " -- extracting http://bit.ly/1IeDNFQ with boilerpipe\n",
      " -- extracting http://bit.ly/1Jj6xP0 with boilerpipe\n",
      " -- extracting http://bit.ly/1GxGlJI with boilerpipe\n",
      " -- extracting http://bit.ly/1eEVRO3 with boilerpipe\n",
      " -- extracting http://bit.ly/1dVhCIv with boilerpipe\n",
      " -- extracting http://bit.ly/1K1UMLt with boilerpipe\n",
      " -- extracting http://bit.ly/1dOi4It with boilerpipe\n",
      " -- extracting http://bit.ly/1H1Z7zk with boilerpipe\n",
      " -- extracting http://bit.ly/1H21kLb with boilerpipe\n",
      " -- extracting http://bit.ly/1InxawC with boilerpipe\n",
      " -- extracting http://bit.ly/1H1Z7zk with boilerpipe\n",
      " -- extracting http://bit.ly/1TuZCVP with boilerpipe\n",
      " -- extracting http://nyti.ms/1JW9BPK with boilerpipe\n",
      " -- failed; extracting http://nyti.ms/1JW9BPK with og\n",
      " -- extracting http://nyti.ms/1R5LJcE with boilerpipe\n",
      " -- failed; extracting http://nyti.ms/1R5LJcE with og\n",
      " -- extracting http://bit.ly/1JOOQ8k with boilerpipe\n",
      " -- extracting http://bit.ly/1Fdb2CX with boilerpipe\n",
      " -- extracting http://bit.ly/1I3OmqH with boilerpipe\n",
      " -- extracting http://bit.ly/1BZqnXA with boilerpipe\n",
      " -- extracting http://bit.ly/1BZqnXA with boilerpipe\n",
      " -- extracting http://bit.ly/1JA0u8F with boilerpipe\n",
      " -- extracting http://bit.ly/1JA0u8F with boilerpipe\n",
      " -- extracting http://bit.ly/1G7CnKI with boilerpipe\n",
      " -- extracting http://bit.ly/1GjbtRg with boilerpipe\n",
      " -- extracting http://bit.ly/1QCIXeY with boilerpipe\n",
      " -- extracting http://bit.ly/1It2WxF with boilerpipe\n",
      " -- extracting http://bit.ly/1It2WxF with boilerpipe\n",
      " -- extracting http://bit.ly/1QxyJfP with boilerpipe\n",
      " -- extracting http://bit.ly/1FyhghZ with boilerpipe\n",
      " -- extracting http://bit.ly/1JrlTiR with boilerpipe\n",
      " -- extracting http://bit.ly/1FU8VaI with boilerpipe\n",
      " -- extracting http://bit.ly/1AM3UlI with boilerpipe\n",
      " -- extracting http://bit.ly/1cwc8Tq with boilerpipe\n",
      " -- extracting http://bit.ly/1M1f1HU with boilerpipe\n",
      " -- extracting http://bit.ly/1KIFfBJ with boilerpipe\n",
      " -- extracting http://bit.ly/1FI5bsR with boilerpipe\n",
      " -- extracting http://bit.ly/1GGQRCX with boilerpipe\n",
      " -- extracting http://bit.ly/1Hynu1I with boilerpipe\n",
      " -- extracting http://bit.ly/1cl9Gz0 with boilerpipe\n",
      " -- extracting http://bit.ly/1cl9Gz0 with boilerpipe\n",
      " -- extracting http://bit.ly/1RoLOKF with boilerpipe\n",
      " -- extracting http://bit.ly/1dybGFE with boilerpipe\n",
      " -- extracting http://bit.ly/1KzJhwd with boilerpipe\n",
      " -- extracting http://bit.ly/1HJnJg0 with boilerpipe\n",
      " -- extracting http://bit.ly/1F8UBYo with boilerpipe\n",
      "Starting account AccuracyInMedia\n",
      " -- extracting http://buff.ly/1eJXqdx with boilerpipe\n",
      " -- extracting http://buff.ly/1eJXGcs with boilerpipe\n",
      " -- extracting http://buff.ly/1SOdTM8 with boilerpipe\n",
      " -- extracting http://buff.ly/1GLpDK1 with boilerpipe\n",
      " -- extracting http://buff.ly/1GJHvF1 with boilerpipe\n",
      " -- extracting http://buff.ly/1e6sjYM with boilerpipe\n",
      " -- extracting http://buff.ly/1dhQlz4 with boilerpipe\n",
      " -- extracting http://buff.ly/1KeqbvI with boilerpipe\n",
      " -- extracting http://buff.ly/1e6shAa with boilerpipe\n",
      " -- extracting http://buff.ly/1SMwAjb with boilerpipe\n",
      " -- extracting http://buff.ly/1BPFjx6 with boilerpipe\n",
      " -- extracting http://buff.ly/1eICRy0 with boilerpipe\n",
      " -- extracting http://buff.ly/1NdNeVj with boilerpipe\n",
      " -- extracting http://buff.ly/1RykYOx with boilerpipe\n",
      " -- extracting https://twitter.com/forbes/status/614123640322400256 with boilerpipe\n",
      " -- extracting http://buff.ly/1GAhHYJ with boilerpipe\n",
      " -- extracting http://buff.ly/1KekHBk with boilerpipe\n",
      " -- extracting http://buff.ly/1IfQP5T with boilerpipe\n",
      " -- extracting http://buff.ly/1SNlSJp with boilerpipe\n",
      " -- extracting https://twitter.com/kristinaribali/status/614082255221161984 with boilerpipe\n",
      " -- extracting http://buff.ly/1BDAcj2 with boilerpipe\n",
      " -- extracting https://twitter.com/laurakfillault/status/614075952763654144 with boilerpipe\n",
      " -- extracting https://twitter.com/anniebeans59/status/614075429108854784 with boilerpipe\n",
      " -- extracting https://twitter.com/kristinaribali/status/614074572980137984 with boilerpipe\n",
      " -- extracting https://twitter.com/allahpundit/status/614073851316547584 with boilerpipe\n",
      " -- extracting https://twitter.com/noahcrothman/status/614072965911715840 with boilerpipe\n",
      " -- extracting https://twitter.com/jpodhoretz/status/614073381554679808 with boilerpipe\n",
      " -- extracting https://twitter.com/ellencarmichael/status/614073735671345152 with boilerpipe\n",
      " -- extracting http://buff.ly/1TOJMFK with boilerpipe\n",
      " -- extracting https://twitter.com/scotusblog/status/614073268337819648 with boilerpipe\n",
      " -- extracting http://buff.ly/1e4Sejl with boilerpipe\n",
      " -- extracting http://buff.ly/1RyWkx6 with boilerpipe\n",
      " -- extracting http://buff.ly/1SMZrnN with boilerpipe\n",
      " -- extracting http://buff.ly/1TOk985 with boilerpipe\n",
      " -- extracting http://buff.ly/1NdMEXv with boilerpipe\n",
      " -- extracting http://buff.ly/1dhJw0C with boilerpipe\n",
      " -- extracting http://buff.ly/1GzMtBa with boilerpipe\n",
      " -- extracting http://buff.ly/1e4S3op with boilerpipe\n",
      " -- extracting http://buff.ly/1dhJIwO with boilerpipe\n",
      " -- extracting http://buff.ly/1BChbxD with boilerpipe\n",
      " -- extracting http://buff.ly/1e3PfHW with boilerpipe\n",
      " -- extracting http://buff.ly/1e3P5R4 with boilerpipe\n",
      " -- extracting http://buff.ly/1LuxZKn with boilerpipe\n",
      " -- extracting http://buff.ly/1Kd50KL with boilerpipe\n",
      " -- extracting http://buff.ly/1GIoWBg with boilerpipe\n",
      " -- extracting http://buff.ly/1RwHZBq with boilerpipe\n",
      " -- extracting http://buff.ly/1e3GptQ with boilerpipe\n",
      " -- extracting http://buff.ly/1SKqrEj with boilerpipe\n",
      " -- extracting http://buff.ly/1QQztC3 with boilerpipe\n",
      " -- extracting http://buff.ly/1e3POBv with boilerpipe\n",
      "Starting account heritage\n",
      " -- extracting http://dailysign.al/1GuJY3U with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GuJY3U with og\n",
      " -- extracting http://dailysign.al/1fGNPEs with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fGNPEs with og\n",
      " -- extracting http://dailysign.al/1fGFFvY with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fGFFvY with og\n",
      " -- extracting http://dailysign.al/1GukRhH with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GukRhH with og\n",
      " -- extracting http://dailysign.al/1GtwDcb with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtwDcb with og\n",
      " -- extracting http://dailysign.al/1GtIG9g with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtIG9g with og\n",
      " -- extracting http://dailysign.al/1GtJkDC with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtJkDC with og\n",
      " -- extracting http://dailysign.al/1GtwDcb with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtwDcb with og\n",
      " -- extracting http://dailysign.al/1GtJkDC with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtJkDC with og\n",
      " -- extracting http://dailysign.al/1GtwDcb with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtwDcb with og\n",
      " -- extracting http://dailysign.al/1GtwDcb with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GtwDcb with og\n",
      " -- extracting http://dailysign.al/1Gt8KRW with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1Gt8KRW with og\n",
      " -- extracting http://dailysign.al/1fBMAGG with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fBMAGG with og\n",
      " -- extracting http://dailysign.al/1GqYjhM with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GqYjhM with og\n",
      " -- extracting http://dailysign.al/1fBeeDy with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fBeeDy with og\n",
      " -- extracting http://dailysign.al/1fBeeDy with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fBeeDy with og\n",
      " -- extracting http://dailysign.al/1fAMqzc with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fAMqzc with og\n",
      " -- extracting http://dailysign.al/1GpNc8V with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GpNc8V with og\n",
      " -- extracting http://dailysign.al/1FIV30N with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1FIV30N with og\n",
      " -- extracting http://dailysign.al/1fxG2sv with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fxG2sv with og\n",
      " -- extracting http://dailysign.al/1JQ71ul with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1JQ71ul with og\n",
      " -- extracting http://dailysign.al/1fBeeDy with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fBeeDy with og\n",
      " -- extracting http://dailysign.al/1K0RKab with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1K0RKab with og\n",
      " -- extracting http://herit.ag/1ITJc3B with boilerpipe\n",
      " -- extracting http://herit.ag/1ITJc3B with boilerpipe\n",
      " -- extracting http://herit.ag/1FA9mDN with boilerpipe\n",
      " -- extracting http://dailysign.al/1fmf8nf with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fmf8nf with og\n",
      " -- extracting http://dailysign.al/1fxDR8p with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fxDR8p with og\n",
      " -- extracting http://dailysign.al/1GmTXrR with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GmTXrR with og\n",
      " -- extracting http://washex.am/1GmOOQD with boilerpipe\n",
      " -- extracting http://dailysign.al/1fxcScV with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fxcScV with og\n",
      " -- extracting http://dailysign.al/1fxa3sn with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fxa3sn with og\n",
      " -- extracting http://dailysign.al/1fwNzYJ with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fwNzYJ with og\n",
      " -- extracting http://dailysign.al/1ftYAK4 with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1ftYAK4 with og\n",
      " -- extracting http://dailysign.al/1ftLEnG with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1ftLEnG with og\n",
      " -- extracting http://dailysign.al/1JS55lk with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1JS55lk with og\n",
      " -- extracting http://dailysign.al/1Gikl6h with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1Gikl6h with og\n",
      " -- extracting http://dailysign.al/1ftkHk6 with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1ftkHk6 with og\n",
      " -- extracting http://dailysign.al/1Giega1 with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1Giega1 with og\n",
      " -- extracting http://dailysign.al/1GcL0Bx with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcL0Bx with og\n",
      " -- extracting http://herit.ag/1GibKAt with boilerpipe\n",
      " -- extracting http://dailysign.al/1GcDYww with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcDYww with og\n",
      " -- extracting http://dailysign.al/1GcL0Bx with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcL0Bx with og\n",
      " -- extracting http://dailysign.al/1GcCpi0 with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcCpi0 with og\n",
      " -- extracting http://dailysign.al/1GcAzxG with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcAzxG with og\n",
      " -- extracting http://dailysign.al/1fqDUmu with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fqDUmu with og\n",
      " -- extracting http://dailysign.al/1fqDpIZ with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1fqDpIZ with og\n",
      " -- extracting http://dailysign.al/1GcL0Bx with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcL0Bx with og\n",
      " -- extracting http://dailysign.al/1GcAcDl with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1GcAcDl with og\n",
      " -- extracting http://dailysign.al/1L7fNoR with boilerpipe\n",
      " -- failed; extracting http://dailysign.al/1L7fNoR with og\n"
     ]
    }
   ],
   "source": [
    "content = {}\n",
    "LIMIT = 50\n",
    "\n",
    "# Try to open content from pickle file\n",
    "try:\n",
    "    content = pickle.load(open(\"crawledContent.pkl\", \"rb\"))\n",
    "except Exception as e:\n",
    "    # Otherwise, loop thru all acounts\n",
    "    for account in accounts:\n",
    "        # Init account to have no content\n",
    "        content[account] = {}\n",
    "        print \"Starting account %s\" % account\n",
    "\n",
    "        # Loop thru all links for the account\n",
    "        for url in links[account][:LIMIT]:\n",
    "            # Attempt to use boilerpipe's article extractor on url\n",
    "            try:\n",
    "                print \" -- extracting %s with boilerpipe\" % url\n",
    "                extractor = Extractor(extractor='ArticleExtractor', url=url)\n",
    "                content[account][url] = extractor.getText()\n",
    "            except Exception as e:\n",
    "                # If there is any issue, try using OpenGraph metadata\n",
    "                try:\n",
    "                    print \" -- failed; extracting %s with og\" % url\n",
    "                    og =  opengraph.OpenGraph(url=url, scrape=True)\n",
    "                    content[account][url] = \"%s. %s\" % (og.title, og.description)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "    \n",
    "    # Save results\n",
    "    pickle.dump(content, open(\"crawledContent.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have crawled some data, lets process it to find some collocations (with bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preProcess(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = [w for w in tokens if not w in stopwords.words('english') and not w.isdigit()]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def displayBigrams(contentDict, threshold=5):\n",
    "    tokens = nltk.wordpunct_tokenize(preProcess(\"\".join([ contentDict[url] for url in contentDict])))\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    finder.apply_freq_filter(threshold)\n",
    "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    return sorted([ (bigram, score) for (bigram, score) in scored ], key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a list of bigrams from AccuracyInMedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'spencer', u'irvine'), 0.016249533059394843),\n",
       " ((u'share', u'author'), 0.0056032872618602915),\n",
       " ((u'aim', u'running'), 0.005042958535674262),\n",
       " ((u'author', u'spencer'), 0.005042958535674262),\n",
       " ((u'blog', u'target'), 0.005042958535674262),\n",
       " ((u'brigham', u'young'), 0.005042958535674262),\n",
       " ((u'currently', u'works'), 0.005042958535674262),\n",
       " ((u'graduated', u'brigham'), 0.005042958535674262),\n",
       " ((u'home', u'blog'), 0.005042958535674262),\n",
       " ((u'international', u'relations'), 0.005042958535674262),\n",
       " ((u'irvine', u'graduated'), 0.005042958535674262),\n",
       " ((u'irvine', u'june'), 0.005042958535674262),\n",
       " ((u'irvine', u'spencer'), 0.005042958535674262),\n",
       " ((u'media', u'related'), 0.005042958535674262),\n",
       " ((u'operations', u'social'), 0.005042958535674262),\n",
       " ((u'related', u'posts'), 0.005042958535674262),\n",
       " ((u'relations', u'currently'), 0.005042958535674262),\n",
       " ((u'running', u'operations'), 0.005042958535674262),\n",
       " ((u'social', u'media'), 0.005042958535674262),\n",
       " ((u'university', u'international'), 0.005042958535674262),\n",
       " ((u'works', u'aim'), 0.005042958535674262),\n",
       " ((u'young', u'university'), 0.005042958535674262),\n",
       " ((u'posts', u'home'), 0.0037355248412401943),\n",
       " ((u'supreme', u'court'), 0.003175196115054165),\n",
       " ((u'king', u'v'), 0.0029884198729921555),\n",
       " ((u'v', u'burwell'), 0.0029884198729921555),\n",
       " ((u'hillary', u'clinton'), 0.002428091146806126),\n",
       " ((u'white', u'house'), 0.0022413149047441168),\n",
       " ((u'e', u'mails'), 0.002054538662682107),\n",
       " ((u'account', u'log'), 0.0018677624206200972),\n",
       " ((u'account', u'sign'), 0.0018677624206200972),\n",
       " ((u'care', u'get'), 0.0018677624206200972),\n",
       " ((u'close', u'sign'), 0.0018677624206200972),\n",
       " ((u'close', u'two'), 0.0018677624206200972),\n",
       " ((u'codes', u'country'), 0.0018677624206200972),\n",
       " ((u'court', u'upholds'), 0.0018677624206200972),\n",
       " ((u'get', u'updates'), 0.0018677624206200972),\n",
       " ((u'happen', u'account'), 0.0018677624206200972),\n",
       " ((u'log', u'close'), 0.0018677624206200972),\n",
       " ((u'obamacare', u'king'), 0.0018677624206200972),\n",
       " ((u'receiving', u'short'), 0.0018677624206200972),\n",
       " ((u'sending', u'receiving'), 0.0018677624206200972),\n",
       " ((u'short', u'codes'), 0.0018677624206200972),\n",
       " ((u'sign', u'close'), 0.0018677624206200972),\n",
       " ((u'sign', u'tune'), 0.0018677624206200972),\n",
       " ((u'sign', u'twitter'), 0.0018677624206200972),\n",
       " ((u'things', u'care'), 0.0018677624206200972),\n",
       " ((u'tune', u'things'), 0.0018677624206200972),\n",
       " ((u'twitter', u'sign'), 0.0018677624206200972),\n",
       " ((u'two', u'way'), 0.0018677624206200972),\n",
       " ((u'updates', u'happen'), 0.0018677624206200972),\n",
       " ((u'upholds', u'obamacare'), 0.0018677624206200972),\n",
       " ((u'way', u'sending'), 0.0018677624206200972),\n",
       " ((u'accuracy', u'academia'), 0.0016809861785580874),\n",
       " ((u'poor', u'kids'), 0.0016809861785580874),\n",
       " ((u'president', u'obama'), 0.0014942099364960778),\n",
       " ((u'state', u'dept'), 0.0014942099364960778),\n",
       " ((u'chief', u'justice'), 0.0011206574523720584),\n",
       " ((u'deal', u'iran'), 0.0011206574523720584),\n",
       " ((u'email', u'address'), 0.0011206574523720584),\n",
       " ((u'extracurricular', u'activities'), 0.0011206574523720584),\n",
       " ((u'rich', u'kids'), 0.0011206574523720584),\n",
       " ((u'abortion', u'clinics'), 0.0009338812103100486),\n",
       " ((u'burwell', u'spencer'), 0.0009338812103100486),\n",
       " ((u'burwell', u'supreme'), 0.0009338812103100486),\n",
       " ((u'clinton', u'campaign'), 0.0009338812103100486),\n",
       " ((u'confederate', u'flag'), 0.0009338812103100486),\n",
       " ((u'country', u'home'), 0.0009338812103100486),\n",
       " ((u'illegal', u'subsidies'), 0.0009338812103100486),\n",
       " ((u'june', u'yup'), 0.0009338812103100486),\n",
       " ((u'justice', u'roberts'), 0.0009338812103100486),\n",
       " ((u'legal', u'share'), 0.0009338812103100486),\n",
       " ((u'majority', u'written'), 0.0009338812103100486),\n",
       " ((u'obama', u'administration'), 0.0009338812103100486),\n",
       " ((u'obamacare', u'illegal'), 0.0009338812103100486),\n",
       " ((u'roberts', u'obamacare'), 0.0009338812103100486),\n",
       " ((u'roger', u'aronoff'), 0.0009338812103100486),\n",
       " ((u'ruled', u'legal'), 0.0009338812103100486),\n",
       " ((u'subscribe', u'home'), 0.0009338812103100486),\n",
       " ((u'subsidies', u'ruled'), 0.0009338812103100486),\n",
       " ((u'target', u'supreme'), 0.0009338812103100486),\n",
       " ((u'vote', u'majority'), 0.0009338812103100486),\n",
       " ((u'written', u'chief'), 0.0009338812103100486),\n",
       " ((u'yup', u'vote'), 0.0009338812103100486)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayBigrams(content['AccuracyInMedia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comapring it with fairmediawatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'new', u'york'), 0.0037562162734102213),\n",
       " ((u'york', u'times'), 0.0026981271823087504),\n",
       " ((u'corporate', u'media'), 0.001481324727542059),\n",
       " ((u'right', u'wing'), 0.0012168024547666914),\n",
       " ((u'united', u'states'), 0.0011638980002116178),\n",
       " ((u'women', u'sports'), 0.0011109935456565443),\n",
       " ((u'white', u'supremacist'), 0.0010051846365463973),\n",
       " ((u'jim', u'naureckas'), 0.0009522801819913237),\n",
       " ((u'washington', u'post'), 0.0009522801819913237),\n",
       " ((u'even', u'though'), 0.0008993757274362501),\n",
       " ((u'op', u'ed'), 0.0008993757274362501),\n",
       " ((u'isis', u'propaganda'), 0.0008464712728811766),\n",
       " ((u'dylann', u'roof'), 0.0007935668183261031),\n",
       " ((u'bernie', u'sanders'), 0.0007406623637710295),\n",
       " ((u'communication', u'effective'), 0.000687757909215956),\n",
       " ((u'fox', u'news'), 0.000687757909215956),\n",
       " ((u'news', u'media'), 0.000687757909215956),\n",
       " ((u'remember', u'respectful'), 0.000687757909215956),\n",
       " ((u'respectful', u'communication'), 0.000687757909215956),\n",
       " ((u'de', u'blasio'), 0.0006348534546608824),\n",
       " ((u'media', u'coverage'), 0.0006348534546608824),\n",
       " ((u'nytimes', u'com'), 0.0006348534546608824),\n",
       " ((u'please', u'remember'), 0.0006348534546608824),\n",
       " ((u'percent', u'said'), 0.0005819490001058089),\n",
       " ((u'barack', u'obama'), 0.0005290445455507353),\n",
       " ((u'hillary', u'clinton'), 0.0005290445455507353),\n",
       " ((u'social', u'media'), 0.0005290445455507353),\n",
       " ((u'western', u'media'), 0.0005290445455507353),\n",
       " ((u'york', u'city'), 0.0005290445455507353),\n",
       " ((u'editor', u'fair'), 0.00047614009099566186),\n",
       " ((u'mass', u'violence'), 0.00047614009099566186),\n",
       " ((u'naureckas', u'editor'), 0.00047614009099566186),\n",
       " ((u'black', u'white'), 0.0004232356364405883),\n",
       " ((u'coverage', u'women'), 0.0004232356364405883),\n",
       " ((u'dean', u'baker'), 0.0004232356364405883),\n",
       " ((u'effective', u'related'), 0.0004232356364405883),\n",
       " ((u'fair', u'org'), 0.0004232356364405883),\n",
       " ((u'far', u'right'), 0.0004232356364405883),\n",
       " ((u'front', u'page'), 0.0004232356364405883),\n",
       " ((u'holy', u'war'), 0.0004232356364405883),\n",
       " ((u'long', u'shot'), 0.0004232356364405883),\n",
       " ((u'media', u'isis'), 0.0004232356364405883),\n",
       " ((u'men', u'sports'), 0.0004232356364405883),\n",
       " ((u'o', u'reilly'), 0.0004232356364405883),\n",
       " ((u'percentage', u'points'), 0.0004232356364405883),\n",
       " ((u'race', u'war'), 0.0004232356364405883),\n",
       " ((u'terrorist', u'attack'), 0.0004232356364405883),\n",
       " ((u'baltimore', u'police'), 0.00037033118188551474),\n",
       " ((u'democratic', u'nomination'), 0.00037033118188551474),\n",
       " ((u'ed', u'snowden'), 0.00037033118188551474),\n",
       " ((u'far', u'left'), 0.00037033118188551474),\n",
       " ((u'income', u'people'), 0.00037033118188551474),\n",
       " ((u'large', u'crowds'), 0.00037033118188551474),\n",
       " ((u'like', u'new'), 0.00037033118188551474),\n",
       " ((u'many', u'people'), 0.00037033118188551474),\n",
       " ((u'military', u'spending'), 0.00037033118188551474),\n",
       " ((u'via', u'twitter'), 0.00037033118188551474),\n",
       " ((u'accuracy', u'reporting'), 0.0003174267273304412),\n",
       " ((u'adam', u'johnson'), 0.0003174267273304412),\n",
       " ((u'california', u'drought'), 0.0003174267273304412),\n",
       " ((u'charleston', u'massacre'), 0.0003174267273304412),\n",
       " ((u'charter', u'schools'), 0.0003174267273304412),\n",
       " ((u'com', u'public'), 0.0003174267273304412),\n",
       " ((u'data', u'collection'), 0.0003174267273304412),\n",
       " ((u'editor', u'margaret'), 0.0003174267273304412),\n",
       " ((u'face', u'nation'), 0.0003174267273304412),\n",
       " ((u'facebook', u'likes'), 0.0003174267273304412),\n",
       " ((u'fair', u'blog'), 0.0003174267273304412),\n",
       " ((u'fairness', u'accuracy'), 0.0003174267273304412),\n",
       " ((u'grace', u'factor'), 0.0003174267273304412),\n",
       " ((u'interest', u'rates'), 0.0003174267273304412),\n",
       " ((u'letters', u'nytimes'), 0.0003174267273304412),\n",
       " ((u'low', u'income'), 0.0003174267273304412),\n",
       " ((u'margaret', u'sullivan'), 0.0003174267273304412),\n",
       " ((u'mass', u'media'), 0.0003174267273304412),\n",
       " ((u'media', u'outlets'), 0.0003174267273304412),\n",
       " ((u'message', u'new'), 0.0003174267273304412),\n",
       " ((u'mr', u'obama'), 0.0003174267273304412),\n",
       " ((u'nancy', u'grace'), 0.0003174267273304412),\n",
       " ((u'national', u'security'), 0.0003174267273304412),\n",
       " ((u'obama', u'administration'), 0.0003174267273304412),\n",
       " ((u'pacific', u'partnership'), 0.0003174267273304412),\n",
       " ((u'people', u'killed'), 0.0003174267273304412),\n",
       " ((u'persuade', u'democrats'), 0.0003174267273304412),\n",
       " ((u'presidential', u'candidate'), 0.0003174267273304412),\n",
       " ((u'public', u'editor'), 0.0003174267273304412),\n",
       " ((u'public', u'nytimes'), 0.0003174267273304412),\n",
       " ((u'roof', u'terrorist'), 0.0003174267273304412),\n",
       " ((u'roof', u'white'), 0.0003174267273304412),\n",
       " ((u'sanders', u'unelectable'), 0.0003174267273304412),\n",
       " ((u'send', u'message'), 0.0003174267273304412),\n",
       " ((u'social', u'security'), 0.0003174267273304412),\n",
       " ((u'street', u'journal'), 0.0003174267273304412),\n",
       " ((u'sullivan', u'public'), 0.0003174267273304412),\n",
       " ((u'ted', u'cruz'), 0.0003174267273304412),\n",
       " ((u'times', u'letters'), 0.0003174267273304412),\n",
       " ((u'took', u'office'), 0.0003174267273304412),\n",
       " ((u'trans', u'pacific'), 0.0003174267273304412),\n",
       " ((u'usa', u'freedom'), 0.0003174267273304412),\n",
       " ((u'wall', u'street'), 0.0003174267273304412),\n",
       " ((u'white', u'supremacists'), 0.0003174267273304412),\n",
       " ((u'year', u'old'), 0.0003174267273304412),\n",
       " ((u'zhome', u'zmail'), 0.0003174267273304412),\n",
       " ((u'zmail', u'tagged'), 0.0003174267273304412),\n",
       " ((u'act', u'violence'), 0.00026452227277536767),\n",
       " ((u'american', u'life'), 0.00026452227277536767),\n",
       " ((u'anti', u'privacy'), 0.00026452227277536767),\n",
       " ((u'baltimore', u'uprising'), 0.00026452227277536767),\n",
       " ((u'black', u'people'), 0.00026452227277536767),\n",
       " ((u'blog', u'zhome'), 0.00026452227277536767),\n",
       " ((u'boston', u'marathon'), 0.00026452227277536767),\n",
       " ((u'daily', u'news'), 0.00026452227277536767),\n",
       " ((u'filed', u'blog'), 0.00026452227277536767),\n",
       " ((u'freedom', u'act'), 0.00026452227277536767),\n",
       " ((u'glenn', u'greenwald'), 0.00026452227277536767),\n",
       " ((u'hillary', u'rodham'), 0.00026452227277536767),\n",
       " ((u'lindsey', u'graham'), 0.00026452227277536767),\n",
       " ((u'mass', u'shooting'), 0.00026452227277536767),\n",
       " ((u'max', u'boot'), 0.00026452227277536767),\n",
       " ((u'one', u'would'), 0.00026452227277536767),\n",
       " ((u'org', u'messages'), 0.00026452227277536767),\n",
       " ((u'originally', u'appeared'), 0.00026452227277536767),\n",
       " ((u'pay', u'little'), 0.00026452227277536767),\n",
       " ((u'people', u'pay'), 0.00026452227277536767),\n",
       " ((u'percent', u'gdp'), 0.00026452227277536767),\n",
       " ((u'police', u'department'), 0.00026452227277536767),\n",
       " ((u'privacy', u'laws'), 0.00026452227277536767),\n",
       " ((u'rand', u'paul'), 0.00026452227277536767),\n",
       " ((u'retirement', u'age'), 0.00026452227277536767),\n",
       " ((u'rodham', u'clinton'), 0.00026452227277536767),\n",
       " ((u'sahara', u'reporters'), 0.00026452227277536767),\n",
       " ((u'see', u'new'), 0.00026452227277536767),\n",
       " ((u'segments', u'american'), 0.00026452227277536767),\n",
       " ((u'times', u'op'), 0.00026452227277536767),\n",
       " ((u'trade', u'deals'), 0.00026452227277536767),\n",
       " ((u'upper', u'income'), 0.00026452227277536767),\n",
       " ((u'vladimir', u'putin'), 0.00026452227277536767),\n",
       " ((u'water', u'shortage'), 0.00026452227277536767),\n",
       " ((u'word', u'terrorism'), 0.00026452227277536767)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayBigrams(content['fairmediawatch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
